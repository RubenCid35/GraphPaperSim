[
    {
        "id": 0,
        "title": "Utilization of whatsapp application as discussion media in blended learning",
        "abstract": "The purpose of this study is to discuss about utilization of Whatsapp application as discussion media in Blended Learning. This study sought to integrate learning technologies to improve the quality of student's learning. Messenger application is used to communicate synchronously, so it can be positioned as a discussion media. This study focused on Whatsapp capabilities can be utilized to conduct in online learning of Blended Learning. This study aims to describe the discussion media. This study through the literature review that outlines the stages of Blended Learning using Whatsapp application as a discussion media by using qualitative methods. The result shows that Whatsapp application utilization as a discussion media in Blended Learning sessions initiated by offline using conventional methods, so the online session focused on the discussion as indicated by dialogue and interaction among participants.",
        "acknowledgment": "This research was supported by Lembaga Penelitian dan Pengabdian Masyarakat (LPPM) Kanjuruhan University. We thank our colleagues from Mathematics Education Department also Science and Technology Faculty of Kanjuruhan University who provided insight and expertise that greatly assisted the research, although they may not agree with all of the conclusions of this paper."
    },
    {
        "id": 1,
        "title": "Moving towards universal health coverage for mental disorders in Ethiopia",
        "abstract": "Background: People with mental disorders in low-income countries are at risk of being left behind during efforts to expand universal health coverage.\nAims:To propose context-relevant strategies for moving towards universal health coverage for people with mental disorders in Ethiopia.\nMethods:We conducted a situational analysis to inform a SWOT analysis of coverage of mental health services and financial risk protection, health system characteristics and the macroeconomic and fiscal environment. In-depth interviews were conducted with five national experts on health financing and equity and analysed using a thematic approach. Findings from the situation analysis and qualitative study were used to develop recommended strategies for adequate, fair and sustainable financing of mental health care in Ethiopia.\nResults:Opportunities for improved financing of mental health care identified from the situation analysis included: a significant mental health burden with evidence from strong local epidemiological data; political commitment to address that burden; a health system with mechanisms for integrating mental health into primary care; and a favourable macro-fiscal environment for investment in human capabilities. Balanced against this were constraints of low current general government health expenditure, low numbers of mental health specialists, weak capacity to plan and implement mental health programmes and low population demand for mental health care. All key informants referred to the under-investment in mental health care in Ethiopia. Respondents emphasised opportunities afforded by positive rates of economic growth in the country and the expansion of community-based health insurance, as well as the need to ensure full implementation of existing task-sharing programmes for mental health care, integrate mental health into other priority programmes and strengthen advocacy to ensure mental health is given due attention.\nConclusion:Expansion of public health insurance, leveraging resources from high-priority SDG-related programmes and implementing existing plans to support task-shared mental health care are key steps towards universal health coverage for mental disorders in Ethiopia. However, external donors also need to deliver on commitments to include mental health within development funding. Future researchers and planners can apply this approach to other countries of sub-Saharan Africa and identify common strategies for sustainable and equitable financing of mental health care.",
        "acknowledgment": "The authors would like to acknowledge the contribution of Caroline Whidden to the first draft of the Ethiopia situational assessment."
    },
    {
        "id": 2,
        "title": "Inverting Visual Representations with Convolutional Networks",
        "abstract": "Feature representations, both hand-designed and learned ones, are often hard to analyze and interpret, even when they are extracted from visual data. We propose a new approach to study image representations by inverting them with an up-convolutional neural network. We apply the method to shallow representations (HOG, SIFT, LBP), as well as to deep networks. For shallow representations our approach provides significantly better reconstructions than existing methods, revealing that there is surprisingly rich information contained in these features. Inverting a deep network trained on ImageNet provides several insights into the properties of the feature representation learned by the network. Most strikingly, the colors and the rough contours of an image can be reconstructed from activations in higher network layers and even from the predicted class probabilities.",
        "acknowledgment": "We acknowledge funding by the ERC Starting Grant VideoLearn (279401). We are grateful to Aravindh Mahendran for sharing with us the reconstructions achieved with the method of Mahendran and Vedaldi [19]. We thank Jost Tobias Springenberg for comments."
    },
    {
        "id": 3,
        "title": "Methods for Interpreting and Understanding Deep Neural Networks",
        "abstract": "This paper provides an entry point to the problem of interpreting a deep neural network model and explaining its predictions. It is based on a tutorial given at ICASSP 2017. It introduces some recently proposed techniques of interpretation, along with theory, tricks and recommendations, to make most efficient use of these techniques on real data. It also discusses a number of practical applications.",
        "acknowledgment": "We gratefully acknowledge discussions and comments on the manuscript by our colleagues Sebastian  Lapuschkin, and Alexander Binder. This work was supported by the Brain Korea 21 Plus Program through the National Research Foundation of Korea; the Institute for Information & Communications Technology Promotion (IITP) grant funded by the Korea government [No. 2017-0-00451]; the Deutsche Forschungsgemeinschaft (DFG) [grant MU 987/17-1]; and the German Ministry for Education and Research as Berlin Big Data Center (BBDC) [01IS14013A]. This publication only reflects the authors views. Funding agencies are not liable for any use that may be made of the information contained herein."
    },
    {
        "id": 4,
        "title": "Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)",
        "abstract": "The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net's internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result-for example, how sensitive a prediction of zebra is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application.",
        "acknowledgment": "We would like to thank Daniel Smilkov for helpful discussions. We thank Alexander Mordvintsev for providing tfzoo code. We also thank Ethan R Elenberg, David Alvarez Melis and an anonymous reviewer for helpful comments and discussions. We thank Alexander Mordvintsev, Chris Olah and Ludwig Schubert for generously allowing us to use their code for DeepDream. Thanks to Christopher for sharing early work on doing attribution to semantically meaningful channels. Work from Nicholas Carlini, on training linear classifiers for non-label concepts on logit-layer activations, was one of our motivations. Finally, we would like to thank Dr. Zahra Rastegar for evaluating diabetic retinopathy results, and provided relevant medical expertise."
    },
    {
        "id": 5,
        "title": "A Survey Of Methods For Explaining Black Box Models",
        "abstract": "In the last years many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness sometimes at the cost of scarifying accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, delineating explicitly or implicitly its own definition of interpretability and explanation. The aim of this paper is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.",
        "acknowledgment": "This work is partially supported by the European Community's H2020 Program under the funding scheme \"INFRAIA-1-2014-2015: Research Infrastructures\", grant agreement 654024, SoBigData, http://www.sobigdata.eu."
    },
    {
        "id": 6,
        "title": "Mathematical Foundations of Computing",
        "abstract": "depth, the performance of the input feature extraction is also enhanced. For example, AlexNet -one of the most representative CNNs, has 650K neurons and 60M related parameters [36]. Also, sophisticated algorithms are proposed to support the training and testing of such a complex network, and the backpropagation method is widely applied to train the CNN parameters through multiple layers [39,44]. Furthermore, to fine-tune the network to specific functions, large pools of labeled data are required for iteratively training the massive neurons and connection weights. So far, many high-performance CNN designs have been proposed, such as AlexNet [36], VGG [63], GoogleNet [66], ResNet [27], etc. Some of the designs can even achieve beyond human-level accuracy on object recognition tasks [61].Although the CNNs can achieve competitive classification accuracy, the CNNs still suffer from high computational cost, slow training speed, and security vulnerability [67,38,4]. One major reason causing these shortcomings is the lack of network interpretability, especially the limited understanding of the internal features learned by each convolutional layer: Mathematically, the convolutional layer neurons (namely the convolution filters) convolve with the input image or the outputs of the previous layer, the results are considered as learned features and recorded in the feature maps. With deeper layers, the neurons are expected to extract higher level features, and eventually converge to the final classification. However, as the CNN training is considered as a black-box process and the neurons are designed in the format of simple matrices, the formation of those neuron values are unpredictable and the neuron meanings are impossible to directly explained. Hence, the poor network interpretability significantly hinders the robustness evaluation of each network layer, the further optimization on the network structure, as well as the network adaptability and transferability to different applications [53,60].A qualitative way to improve the network interpretability is the network visualization, which translates the internal features into visually perceptible image patterns. This visualization process is referred from the human visual cortex system analysis: In a human brain, the human visual cortex is embedded in multiple vision neuron areas [57]. In each vision neuron area, numerous neurons selectively respond to different features, such as colors, edges, and shapes [35,54]. To explore the relationship between the neurons and features, researchers usually find the preferred stimulus to identify individual kind of the response and illustrate the response to certain visual patterns. The CNN visualization also follows such an analytical approach to realize the CNN interpretability.Up to now, many effective network visualization works have been proposed in the literature, and several representative methods are widely adopted: 1) Erhan et al. proposed the Activation Maximization to interpret traditional shallow networks [14,28,68]. Later, this method was further improved by Simonyan et al., which synthesized an input image pattern with the maximum activation of a single CNN neuron for visualization [62]. This fundamental method was also extended by many other works with different regularizers for interpretability improvement of the synthesized image patterns [71,52,50]. 2) Besides the visualization of a single neuron, Mahendran et al. revealed the CNN internal features in the layer level [46,47]. The Network Inversion was proposed to reconstruct an input image based on multiple neurons' activation to illustrate a comprehensive feature map learned by each single CNN layer. 3) Rather than reconstructing an input image for feature visualization, Zeiler et al. proposed the Deconvolutional Neural Network based Visualization (DeconvNet) [72], which utilized the DeconvNet framework to",
        "acknowledgment": "Acknowledgments. This work was supported in part by NSF CNS-1717775."
    },
    {
        "id": 7,
        "title": "Explaining Explanations: An Overview of Interpretability of Machine Learning",
        "abstract": "There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.",
        "acknowledgment": "The work was partially funded by DARPA XAI program FA8750-18-C0004, the National Science Foundation under Grants No. 1524817, the MIT-IBM Watson AI Lab, and the Toyota Research Institute (TRI). The authors also wish to express their appreciation for Jonathan Frankle for sharing his insightful feedback on earlier versions of the manuscript."
    },
    {
        "id": 8,
        "title": "Understanding Neural Networks via Feature Visualization: A survey",
        "abstract": "A neuroscience method to understanding the brain is to find and study the preferred stimuli that highly activate an individual cell or groups of cells. Recent advances in machine learning enable a family of methods to synthesize preferred stimuli that cause a neuron in an artificial or biological brain to fire strongly. Those methods are known as Activation Maximization (AM) [ ] or Feature Visualization via Optimization. In this chapter, we ( ) review existing AM techniques in the literature; ( ) discuss a probabilistic interpretation for AM; and ( ) review the applications of AM in debugging and explaining networks.",
        "acknowledgment": "Acknowledgments Anh Nguyen is supported by Amazon Research Credits, Auburn University, and donations from Adobe Systems Inc and Nvidia."
    },
    {
        "id": 9,
        "title": "Intrinsic Dimension, Persistent Homology and Generalization in Neural Networks",
        "abstract": "Disobeying the classical wisdom of statistical learning theory, modern deep neural networks generalize well even though they typically contain millions of parameters. Recently, it has been shown that the trajectories of iterative optimization algorithms can possess fractal structures, and their generalization error can be formally linked to the complexity of such fractals. This complexity is measured by the fractal's intrinsic dimension, a quantity usually much smaller than the number of parameters in the network. Even though this perspective provides an explanation for why overparametrized networks would not overfit, computing the intrinsic dimension (e.g., for monitoring generalization during training) is a notoriously difficult task, where existing methods typically fail even in moderate ambient dimensions. In this study, we consider this problem from the lens of topological data analysis (TDA) and develop a generic computational tool that is built on rigorous mathematical foundations. By making a novel connection between learning theory and TDA, we first illustrate that the generalization error can be equivalently bounded in terms of a notion called the 'persistent homology dimension' (PHD), where, compared with prior work, our approach does not require any additional geometrical or statistical assumptions on the training dynamics. Then, by utilizing recently established theoretical results and TDA tools, we develop an efficient algorithm to estimate PHD in the scale of modern deep neural networks and further provide visualization tools to help understand generalization in deep learning. Our experiments show that the proposed approach can efficiently compute a network's intrinsic dimension in a variety of settings, which is predictive of the generalization error.",
        "acknowledgment": "Umut Şimşekli's research is supported by the French government under management of Agence Nationale de la Recherche as part of the \"Investissements d'avenir\" program, reference ANR-19-P3IA-0001 (PRAIRIE 3IA Institute)."
    },
    {
        "id": 10,
        "title": "Enhancing Counterfactual Explanation Search with Diffusion Distance and Directional Coherence",
        "abstract": "A pressing issue in the adoption of AI models is the increasing demand for more human-centric explanations of their predictions. To advance towards more human-centric explanations, understanding how humans produce and select explanations has been beneficial. In this work, inspired by insights of human cognition we propose and test the incorporation of two novel biases to enhance the search for effective counterfactual explanations. Central to our methodology is the application of diffusion distance, which emphasizes data connectivity and actionability in the search for feasible counterfactual explanations. In particular, diffusion distance effectively weights more those points that are more interconnected by numerous short-length paths. This approach brings closely connected points nearer to each other, identifying a feasible path between them. We also introduce a directional coherence term that allows the expression of a preference for the alignment between the joint and marginal directional changes in feature space to reach a counterfactual. This term enables the generation of counterfactual explanations that align with a set of marginal predictions based on expectations of how the outcome of the model varies by changing one feature at a time. We evaluate our method, named Coherent Directional Counterfactual Explainer (CoDiCE), and the impact of the two novel biases against existing methods such as DiCE, FACE, Prototypes, and Growing Spheres. Through a series of ablation experiments on both synthetic and real datasets with continuous and mixed-type features, we demonstrate the effectiveness of our method.",
        "acknowledgment": "Acknowledgments. This research was supported by the Estonian Research Council Grants PRG1604, the European Union's Horizon 2020 Research and Innovation Programme under Grant Agreement No. 952060 (Trust AI), by the Estonian Centre of Excellence in Artificial Intelligence (EXAI), by the Estonian Ministry of Education and Research."
    },
    {
        "id": 11,
        "title": "Explainable LightGBM Approach for Predicting Myocardial Infarction Mortality",
        "abstract": "Myocardial Infarction is a main cause of mortality globally, and accurate risk prediction is crucial for improving patient outcomes. Machine Learning techniques have shown promise in identifying high-risk patients and predicting outcomes. However, patient data often contain vast amounts of information and missing values, posing challenges for feature selection and imputation methods. In this article, we investigate the impact of the data preprocessing task and compare three ensembles boosted tree methods to predict the risk of mortality in patients with myocardial infarction. Further, we use the Tree Shapley Additive Explanations method to identify relationships among all the features for the performed predictions, leveraging the entirety of the available data in the analysis. Notably, our approach achieved a superior performance when compared to other existing machine learning approaches, with an F1-score of 91,2% and an accuracy of 91,8% for LightGBM without data preprocessing.",
        "acknowledgment": "VI. ACKNOWLEDGMENT This work was partially financed by the Coordenac ¸ão de Aperfeic ¸oamento de Pessoal de Nível Superior -Brasil (CAPES), and by Fundac ¸ão de Amparo à Pesquisa do Estado de São Paulo (FAPESP) # 2023/06737-7 and INCT (CAPES #88887.136349/2017-00, CNPQ #465755/2014-3)."
    },
    {
        "id": 12,
        "title": "Adversarial Diffusion Distillation",
        "abstract": "Figure 1. Generating high-fidelity 512 2 images in a single step. All samples are generated with a single U-Net evaluation trained with adversarial diffusion distillation (ADD).",
        "acknowledgment": "We would like to thank Jonas Müller for feedback on the draft, the proof, and typesetting; Patrick Esser for feedback on the proof and building an early model demo; Frederic Boesel for generating data and helpful discussions; Minguk Kang and Taesung Park for providing GigaGAN samples; Richard Vencu, Harry Saini, and Sami Kama for maintaining the compute infrastructure; Yara Wald for creative sampling support; and Vanessa Sauer for her general support."
    },
    {
        "id": 13,
        "title": "Learning Transferable Visual Models From Natural Language Supervision",
        "abstract": "State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/OpenAI/CLIP.",
        "acknowledgment": "We'd like to thank the millions of people involved in creating the data CLIP is trained on. We'd also like to thank Susan Zhang for her work on image conditional language models while at OpenAI, Ishaan Gulrajani for catching an error in the pseudocode, and Irene Solaiman, Miles Brundage, and Gillian Hadfield for their thoughtful feedback on the broader impacts section of the paper. We are also grateful to the Acceleration and Supercomputing teams at OpenAI for their critical work on software and hardware infrastructure this project used. Finally, we'd also like to thank the developers of the many software packages used throughout this project including, but not limited, to Numpy (Harris et al., 2020), SciPy (Virtanen et al., 2020), ftfy (Speer, 2019), Tensor-Flow (Abadi et al., 2016), PyTorch (Paszke et al., 2019), pandas (pandas development team, 2020), and scikit-learn (Pedregosa et al., 2011)."
    },
    {
        "id": 14,
        "title": "Consistency Models",
        "abstract": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation. To overcome this limitation, we propose consistency models, a new family of models that generate high quality samples by directly mapping noise to data. They support fast one-step generation by design, while still allowing multistep sampling to trade compute for sample quality. They also support zero-shot data editing, such as image inpainting, colorization, and super-resolution, without requiring explicit training on these tasks. Consistency models can be trained either by distilling pre-trained diffusion models, or as standalone generative models altogether. Through extensive experiments, we demonstrate that they outperform existing distillation techniques for diffusion models in one-and few-step sampling, achieving the new state-ofthe-art FID of 3.55 on CIFAR-10 and 6.20 on ImageNet 64 ˆ64 for one-step generation. When trained in isolation, consistency models become a new family of generative models that can outperform existing one-step, non-adversarial generative models on standard benchmarks such as CIFAR-10, ImageNet 64 ˆ64 and LSUN 256 ˆ256.",
        "acknowledgment": "We thank Alex Nichol for reviewing the manuscript and providing valuable feedback, Chenlin Meng for providing stroke inputs needed in our stroke-guided image generation experiments, and the OpenAI Algorithms team."
    },
    {
        "id": 15,
        "title": "COVID-19 and children's health in the United States: Consideration of physical and social environments during the pandemic",
        "abstract": "Public health measures necessary to counteract the coronavirus disease 2019 (COVID-19) pandemic have resulted in dramatic changes in the physical and social environments within which children grow and develop. As our understanding of the pathways for viral exposure and associated health outcomes in children evolves, it is critical to consider how changes in the social, cultural, economic, and physical environments resulting from the pandemic could affect the development of children. This review article considers the environments and settings that create the backdrop for children's health in the United States during the COVID-19 pandemic, including current threats to child development that stem from: A) change in exposures to environmental contaminants such as heavy metals, pesticides, disinfectants, air pollution and the built environment; B) changes in food environments resulting from adverse economic repercussion of the pandemic and limited reach of existing safety nets; C) limited access to children's educational and developmental resources; D) changes in the social environments at the individual and household levels, and their interplay with family stressors and mental health; E) social injustice and racism. The environmental changes due to COVID-19 are overlaid onto existing environmental and social disparities. This results in disproportionate effects among children in low-income settings and among populations experiencing the effects of structural racism. This article draws attention to many environments that should be considered in current and future policy responses to protect children's health amid pandemics.",
        "acknowledgment": "The authors would like to thank Jermesha Smith and Meghan Ryan, LCPC, for helpful discussions about working with families during the pandemic, and Eduardo Gonzalez for assisting with the referencing of this manuscript."
    },
    {
        "id": 16,
        "title": "Zero-Shot Text-to-Image Generation",
        "abstract": "Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.",
        "acknowledgment": "We would like to thank Matthew Knight for reviewing the code release for this work, and Rewon Child, John Schulman, Heewoo Jun, and Prafulla Dhariwal for helpful early feedback on the paper. We would also like to thank Jong Wook Kim for writing the PyTorch package for the contrastive model described in Radford et al. (2019) that we used to rerank the samples from our model."
    },
    {
        "id": 17,
        "title": "MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING",
        "abstract": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have nearrandom accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
        "acknowledgment": "We would like to thank the following for their helpful comments: Oyvind Tafjord, Jan Leike, David Krueger, Alex Tamkin, Girish Sastry, and Henry Zhu. DH is supported by the NSF GRFP Fellowship and an Open Philanthropy Project Fellowship. This research was also supported by the NSF Frontier Award 1804794."
    },
    {
        "id": 18,
        "title": "Common errors in Generative AI systems used for knowledge extraction in the climate action domain",
        "abstract": "Large Language Models (LLMs) and, more specifically, the Generative Pre-Trained Transformers (GPT) can help stakeholders in climate action to explore digital knowledge bases, extract and utilize climate action knowledge in sustainable manner. However, LLMs are \"probabilistic models of knowledge bases\" that excel at generating convincing texts but cannot be entirely relied upon due to the probabilistic nature of the information produced. This brief report illustrates the problem space with examples of LLM responses to some of the questions of relevance to the climate action.Prompt-2 -> Let's test this approach by looking at a climate-related question together and then checking the sources that you use to answer my question. Could you tell me what the environmental impact of AI generated language models is and provide scientific references in the text and links to the sources mentioned?ChatGPT3.5-turbo-> Certainly! The environmental impact of AI-generated language models is a topic of concern due to the significant computational resources required to train and run these models. Let's explore this issue, and I'll provide you with scientific references to support the information.Environmental Impact of AI-Language Models: AI-generated language models, like GPT-3 and its successors, have notable environmental impacts primarily in two areas:Energy Consumption: Training large language models requires substantial computational power, including high-performance GPUs and TPUs. These models undergo training processes that can last for weeks or even months, consuming vast amounts of electricity. The energy demand associated with training deep learning models contributes to greenhouse gas emissions.Carbon Emissions: The electricity used for training and running AI models is often generated from fossil fuels, which release carbon dioxide (CO2) into the atmosphere. As a result, AI language models can indirectly contribute to carbon emissions and global warming.Scientific References: Here are some scientific references to support the information above:",
        "acknowledgment": "Work leading to this paper has been performed in the scope of the EU-funded project MAIA, under the grant agreement ID: 101056935."
    },
    {
        "id": 19,
        "title": "PERCEPTIONS OF GEORGIAN CONSUMERS ABOUT HEALTHY NUTRITION",
        "abstract": "The paper studies the role of healthy nutrition in ensuring food security and sustainable development of consumers. The main focus is on awareness consumers about healthy nutrition, which is presented, as the most important issue of social marketing. One of the important factors of changing healthy behavior are increasing awareness in healthy nutrition among the general publics. On the basis of the research revealed sources of information, also levels of consumers' interest, awareness and perception regarding healthy nutrition. From the point of view of the relation to healthy nutrition, in the work is determined influence of the age, education and income on consumers healthy nutrition awareness. In the paper is given the impact of consumers' awareness of healthy nutrition on the decision-making to purchase. On the basis of the conducted study, conclusions have been drawn that give a possibility of global vision on the attitude of the Georgian consumers towards healthy nutrition.",
        "acknowledgment": "Acknowledgment. The paper based on the project \"Influence of Food Labeling on Changing Consumer Behavior (in the context of the association of Georgia with the European Union)\" conducted at the Marketing Department of Ivane Javakhishvili Tbilisi State University."
    },
    {
        "id": 20,
        "title": "Multi-Task Mutual Learning for Joint Sentiment Classification and Topic Detection",
        "abstract": "Recently, advances in neural network approaches have achieved many successes in both sentiment classification and probabilistic topic modeling. On the one hand, latent topics derived from the global context of documents could be helpful in capturing more accurate word semantics and hence could potentially improve the sentiment classification accuracy. On the other hand, the word-level attention vectors obtained during the learning of sentiment classifiers could carry word-level polarity information and can be used to guide the discovery of topics in topic modeling. This paper proposes a multi-task learning framework which jointly learns a sentiment classifier and a topic model by making the word-level latent topic distributions in the topic model to be similar to the word-level attention vectors in sentiment classifiers through mutual learning. Experimental results on the Yelp and IMDB datasets verify the superior performance of the proposed framework over strong baselines on both sentiment classification and topic modeling. The proposed framework also extracts more interpretable topics compared to other conventional topic models and neural topic models.",
        "acknowledgment": "This work was supported by EU-H2020 (grant no. 794196), EPSRC (grant no. EP/T017112/1), Innovate UK (grant no. 103652), National Natural Science Foundation of China 61876053, 61632011, Shenzhen Foundational Research Funding JCYJ20180507183527919."
    },
    {
        "id": 21,
        "title": "Detection of Potholes Using a Deep Convolutional Neural Network",
        "abstract": "Poor road conditions like cracks and potholes can cause inconvenience to passengers, damage to vehicles, and accidents. Detecting those obstacles has become relevant due to the rise of the autonomous vehicle. Although previous studies used various sensors and applied different image processing techniques, performance is still significantly lacking, especially when compared to the tremendous leaps in performance with computer vision and deep learning. This research addresses this issue with the help of deep learning-based techniques. We applied the You Only Look Once version 2 (YOLOv2) detector and propose a deep convolutional neural network (CNN) based on YOLOv2 with a different architecture and two models. Despite a limited amount of learning data and the challenging nature of pothole images, our proposed architecture is able to obtain a significant increase in performance over YOLOv2 (from 60.14% to 82.43% average precision).",
        "acknowledgment": "This work was supported by an INHA UNIVERSITY Research Grant."
    },
    {
        "id": 22,
        "title": "Association of cardiovascular emerging risk factors with acute coronary syndrome and stroke: A case-control study",
        "abstract": "In this study, we estimated the risk of acute coronary syndrome and stroke associated with several emerging cardiovascular risk factors. This was a case-control study, where an age -and sex-matched acute coronary syndrome group and stroke group were compared with controls. Demographic and clinical data were collected through patient interviews, and blood samples were taken for analysis. In the bivariate analysis, all cardiovascular risk factors analyzed showed as predictors of acute coronary syndrome and stroke, except total cholesterol and smoking. In the multivariate logistic regression model for acute coronary syndrome, hypertension and body mass index, N-terminal section brain natriuretic peptide and pregnancy-associated plasma protein-A were independent predictors. For stroke, the predictors were hypertension, diabetes mellitus, body mass index, and N-terminal section brain natriuretic peptide. Controlling for age, sex, and classical cardiovascular risk factors, N-terminal section brain natriuretic peptide and pregnancy-associated plasma protein-A were independent emerging cardiovascular risk factors for acute coronary syndrome, but pregnancy-associated plasma protein-A was not for stroke. High levels of cardiovascular risk factors in individuals with no episodes of cardiovascular disease requires the implementation of prevention programs, given that at least half of them are modifiable.",
        "acknowledgment": "This research was conducted with funding from the Health Agency of Health South of Grenada, Spain, and was partially funded by the MTM2013-47929-P project from \"Secretariat of State for Research, Development and Innovation, Ministry of Economy and Competitiveness\", Spain."
    },
    {
        "id": 23,
        "title": "MASTODON OVER MAMMON Towards publicly owned scholarly knowledge",
        "abstract": "",
        "acknowledgment": "We are indebted to Hillel Chiel for critical comments at a crucial stage of writing, as well as to Michael Eisen for providing most of the references on scholarly societies attacking modernization. We thank three anonymous reviewers for their helpful suggestions."
    },
    {
        "id": 24,
        "title": "An insight of medical students on the use of lectures in the curriculum: A pilot study",
        "abstract": "Introduction:Many hours of a student's life are spent in a lecture hall, \"the supposed place of education, growth, and understanding.\" Likewise, countless hours are spent by faculty and staff in preparation for these lectures. The objective of the study was to discover the perceptions of medical students on current trends in lecture delivery. The study also arises from the fact that there is a dearth of data in Mauritius.\nMethods:A cross-sectional observational analytic pilot study was conducted via the method of a semi-structured closed-ended questionnaire. A 5-point Likert scale (strongly disagree, disagree, neither agree nor disagree, agree, strongly agree) was used to record the responses. Two male and two female students were chosen via a convenience sampling technique from all the semesters viz. Semester one to semester ten.\nResults:Lectures reduced anxiety with regards to study material was \"strongly agreed\" by 46.4% Indians, whereas 62.5% of South Africans and 50% Mauritians opted the \"agree\" option. As far as faculty as role models were concerned, 15 (37.5%) of students [males 7 (35%); females 8 (40%)] strongly agreed with the option. Preference of structural approach and the correlation with gender was found to be statistically significant P <0.05.\nConclusion:The data both suggest and prove that students are ultimately still in favor of lectures; however, duration, content, and lecture formats were critically appraised. Although the study is a pilot study, which was conducted on a small sample size, the findings can be utilized as baseline data for further investigations.",
        "acknowledgment": "We extend our earnest appreciation to Chairman Mr. RPN Singh and Prof. Namrata Chhabra, Principal In-charge, Prof. Sushil Dawka, Sir Seewoosagur Ramgoolam Medical College, Mauritius, for providing us with immense support and guidance to conduct the research study effectively. We are also thankful to Dr. Brijesh Sathian, Scientist, Department of geriatrics and long-term care, Rumailah Hospital, Doha, Qatar, for generous help. We extend our thanks to those who participated in the research."
    },
    {
        "id": 25,
        "title": "Mixtral of Experts",
        "abstract": "We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts). For every token, at each layer, a router network selects two experts to process the current state and combine their outputs. Even though each token only sees two experts, the selected experts can be different at each timestep. As a result, each token has access to 47B parameters, but only uses 13B active parameters during inference. Mixtral was trained with a context size of 32k tokens and it outperforms or matches Llama 2 70B and GPT-3.5 across all evaluated benchmarks. In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarks. We also provide a model finetuned to follow instructions, Mixtral 8x7B -Instruct, that surpasses GPT-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B -chat model on human benchmarks. Both the base and instruct models are released under the Apache 2.0 license.",
        "acknowledgment": "We thank the CoreWeave and Scaleway teams for technical support as we trained our models. We are grateful to NVIDIA for supporting us in integrating TensorRT-LLM and Triton and working alongside us to make a sparse mixture of experts compatible with TensorRT-LLM."
    },
    {
        "id": 26,
        "title": "Attention Is All You Need",
        "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. * Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation and became the other person involved in nearly every detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.† Work performed while at Google Brain.‡ Work performed while at Google Research.",
        "acknowledgment": "Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful comments, corrections and inspiration."
    },
    {
        "id": 27,
        "title": "The proposed EU Directives for AI liability leave worrying gaps likely to impact medical AI",
        "abstract": "Two newly proposed Directives impact liability for artificial intelligence in the EU: a Product Liability Directive (PLD) and an AI Liability Directive (AILD). While these proposed Directives provide some uniform liability rules for AI-caused harm, they fail to fully accomplish the EU's goal of providing clarity and uniformity for liability for injuries caused by AI-driven goods and services. Instead, the Directives leave potential liability gaps for injuries caused by some black-box medical AI systems, which use opaque and complex reasoning to provide medical decisions and/or recommendations. Patients may not be able to successfully sue manufacturers or healthcare providers for some injuries caused by these black-box medical AI systems under either EU Member States' strict or fault-based liability laws. Since the proposed Directives fail to address these potential liability gaps, manufacturers and healthcare providers may have difficulty predicting liability risks associated with creating and/or using some potentially beneficial black-box medical AI systems.",
        "acknowledgment": "This work was funded by the European Union (Grant Agreement no. 101057321). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the Health and Digital Executive Agency. Neither the European Union nor the granting authority can be held responsible for them. S.G. also reports grants from the European Union (Grant Agreement no. 101057099), the National Institute of Biomedical Imaging and Bioengineering (NIBIB) of the National Institutes of Health (Grant Agreement no. 3R01EB027650-03S1), and the Rock Ethics Institute at Penn State University."
    },
    {
        "id": 28,
        "title": "An Explainable Intervention Prediction for Trauma Patients",
        "abstract": "Trauma patients are commonly severely injured people that require systematic evaluation and rapid response. This paper presents work in progress for an explainable, late fusion and Deep Learningbased prediction system for interventions in Intensive Care Units (ICU) by employing neurosymbolic Explainable Artificial Intelligence (XAI) techniques.",
        "acknowledgment": "This work has received funding from the European Union's H2020 RIA projects INGENIOUS (833435) and NIGHTINGALE (101021957). Content reflects only the authors' view and the Research Executive Agency (REA) and the European Commission are not responsible for any use that may be made of the information it contains."
    },
    {
        "id": 29,
        "title": "Unusual Features of the SARS-CoV-2 Genome Suggesting Sophisticated Laboratory Modification Rather Than Natural Evolution and Delineation of Its Probable Synthetic Route",
        "abstract": "The COVID-19 pandemic caused by the novel coronavirus SARS-CoV-2 has led to over 910,000 deaths worldwide and unprecedented decimation of the global economy. Despite its tremendous impact, the origin of SARS-CoV-2 has remained mysterious and controversial. The natural origin theory, although widely accepted, lacks substantial support. The alternative theory that the virus may have come from a research laboratory is, however, strictly censored on peer-reviewed scientific journals. Nonetheless, SARS-CoV-2 shows biological characteristics that are inconsistent with a naturally occurring, zoonotic virus. In this report, we describe the genomic, structural, medical, and literature evidence, which, when considered together, strongly contradicts the natural origin theory. The evidence shows that SARS-CoV-2 should be a laboratory product created by using bat coronaviruses ZC45 and/or ZXC21 as a template and/or backbone. Building upon the evidence, we further postulate a synthetic route for SARS-CoV-2, demonstrating that the laboratory-creation of this coronavirus is convenient and can be accomplished in approximately six months. Our work emphasizes the need for an independent investigation into the relevant research laboratories. It also argues for a critical look into certain recently published data, which, albeit problematic, was used to support and claim a natural origin of SARS-CoV-2. From a public health perspective, these actions are necessary as knowledge of the origin of SARS-CoV-2 and of how the virus entered the human population are of pivotal importance in the fundamental control of the COVID-19 pandemic as well as in preventing similar, future pandemics.",
        "acknowledgment": "We would like to thank Daoyu Zhang for sharing with us the findings of mutations in the E proteins in different sub-groups of β coronaviruses. We also thank all the anonymous scientists and other individuals, who have contributed in uncovering various facts associated with the origin of SARS-CoV-2."
    }
]